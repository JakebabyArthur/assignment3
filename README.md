# assignment3
# Algorithmic Weekly Trading of Alphabet (GOOG) via Multi-Level ML Predictions

**Author:** *Your Name*
**Date:** Aug 2025
**Course:** *Financial Engineering* (Programming Assignment – Automated Trading)
**License:** MIT (or your choice)

---

## Abstract

This project implements an automated, **weekly** trading strategy for Alphabet (**GOOG**). A machine-learning model forecasts the **next 10-trading-day** log return using technical & statistical features; a **policy layer** maps the prediction to discrete actions (long/flat/short) using **risk-tuned percentiles** and a **regime filter**. The program is robust to data issues (rate limits, column variants, duplicate dates) and maintains a persistent **position state** to only rebalance on Fridays.
Deliverables include this repository, a reproducible Python program, generated outputs (JSON/CSV/figures), and a research report (PDF).

---

## Repo Contents

```
.
├─ README.md                  # you’re reading this
├─ report.md                  # research report (export this to report.pdf)
├─ Google_Trading.py          # main trading program (stateful, weekly)
├─ make_plots.py              # turns the signals ledger into figures
├─ environment.yml            # conda environment
├─ data/
│  └─ goog_historical_data.csv   # initial seed history (daily OHLCV)
├─ live_state/                # generated at runtime (commit small samples)
│  ├─ model_info_GOOG.json       # latest signal (human-readable JSON)
│  ├─ pred_history_GOOG.csv      # weekly prediction history (for percentiles)
│  ├─ position_state.json        # current position & active levels
│  └─ signals_ledger_GOOG.csv    # time series of actions/positions
└─ figs/                      # generated by make_plots.py
   ├─ equity_curve.png
   ├─ drawdown.png
   └─ signals_last_6m.png
```

> 🔎 **Submission note:** The grader should find **all deliverables** here: the program, outputs, figures, and **`report.pdf`** exported from `report.md`.

---

## Quick Start

### 1) Create the environment

```bash
conda env create -f environment.yml
conda activate goog-trader
```

### 2) Run the trading script

```bash
python Google_Trading.py
```

Outputs land in `live_state/`:

* `model_info_GOOG.json` – latest signal snapshot
* `signals_ledger_GOOG.csv` – time series of signals/actions/positions
* `pred_history_GOOG.csv` – past weekly predictions (for percentiles)

### 3) Generate figures

```bash
python make_plots.py
```

See `figs/equity_curve.png`, `figs/drawdown.png`, `figs/signals_last_6m.png`.

### 4) Export the research report to PDF

* Open `report.md` and export to **`report.pdf`** (VS Code: “Markdown: Print to PDF”, or Pandoc).

---

## Problem Description (What this program solves)

* **Objective:** Automated trading for GOOG with a **multi-level pipeline**

  1. Predict the **10-day** forward log return on the latest bar.
  2. Convert the prediction into a **rolling percentile** vs. past weekly predictions (leakage-safe).
  3. Map percentile to action using a **risk band** (e.g., *moderate*: long ≥ 80th, short ≤ 20th).
  4. Apply a **regime filter** so we only long in uptrends and short in downtrends.
  5. **Rebalance weekly (Fridays)**; maintain the prior position on other days.

* **Outputs:** Human-readable JSON signal, signals ledger CSV, historical prediction CSV, and plotting figures.

---

## Data Preparation & Robust Loader

* **Primary source:** `data/goog_historical_data.csv` (daily OHLCV).
* **Backfill:** Tries **Yahoo Finance** (GOOG, then **GOOGL**) and **Stooq** (via `pandas-datareader`) if rate-limited.
* **Normalization:**

  * Standardizes columns → `Open, High, Low, Close, Volume`.
  * Drops duplicates; coerces any accidental (N,1) DataFrame columns to 1-D Series.
  * Ensures a strictly increasing **Date** index, timezone-naive and **normalized to midnight**, which aligns with weekly rebalance checks.

---

## Features, Target, and Leakage Controls

* **Features (daily):** 1/5/10-day log returns, rolling vol (10/20), MA ratios (10/20/50/200), RSI(14), MACD (line/signal/hist), Bollinger z-score vs. MA20 & stdev20, volume z-score, intraday range (H–L)/Close, and (Close–Open)/Open.

* **Target:**

  $$
  y_t = \log(C_{t+10}) - \log(C_t)
  $$

  We **build features for all dates**, but labels only exist where $C_{t+10}$ is known, letting us **predict on the newest bar** without look-ahead.

* **Leakage controls:**

  * Train on the most recent **252 labeled** rows (≈ 1 trading year), **excluding the latest unlabeled bar**.
  * Percentiles are computed against **stored past weekly predictions** and **explicitly exclude today**.

---

## Model & Policy (Multi-Level Prediction → Action)

* **Model:** `HistGradientBoostingRegressor` (sklearn) inside a pipeline
  `Imputer(median) → StandardScaler(with_mean=False) → HGBR(max_depth=6, lr=0.05, max_iter=400)`.

* **Percentile mapping (risk bands):**

| Band     | Buy (Long) if pct ≥ | Short if pct ≤ |
| -------- | ------------------- | -------------- |
| low      | 0.90                | 0.10           |
| moderate | 0.80                | 0.20           |
| high     | 0.70                | 0.30           |

> Set in code via `RISK_BAND` and `RISK_BANDS`.

* **Regime filter:** 126-day momentum $\frac{C_t}{C_{t-126}}-1$

  * Uptrend (≥ 0): block **shorts**
  * Downtrend (≤ 0): block **longs**
    (Threshold can be softened, e.g., ±5%.)

* **Rebalance cadence:** `REBALANCE="W-FRI"` – only change exposure on Fridays.
  On other days, we **carry the prior position** (`live_state/position_state.json` keeps it).

* **ATR-based prompts:** Suggested stop/take (not orders) based on **ATR(14)**:

  * Long: stop = 1.5×ATR below, take = 3×ATR above
  * Short: stop = 1.5×ATR above, take = 3×ATR below

---

## Configuration (in `Google_Trading.py`)

```python
TICKER = "GOOG"
ALT_TICKER = "GOOGL"
REBALANCE = "W-FRI"     # or "D" for daily
LOOKBACK_D = 252
FWD_HORIZON_D = 10
PCTL_WINDOW_WEEKS = 20
LONG_ONLY = False       # True => long/flat only
USE_REGIME_FILTER = True
REGIME_WINDOW = 126
RISK_BAND = "moderate"  # "low" | "moderate" | "high"
ATR_WINDOW = 14
STOP_MULT = 1.5
TAKE_MULT = 3.0
```

---

## Program Outputs

* **`live_state/model_info_GOOG.json`** (latest signal snapshot)

  ```json
  {
    "timestamp": "2025-08-15 00:00:00",
    "ticker": "GOOG",
    "close": 204.91,
    "predicted_log_return_next_10d": 0.036017,
    "pred_percentile_20w": 0.0000,
    "risk_band": "moderate",
    "rebalance": "W-FRI",
    "long_only": false,
    "regime_filter": true,
    "signal_action": "HOLD/FLAT",
    "action_applied": "REBALANCE→FLAT",
    "current_position": 0,
    "atr_pct": 0.0212,
    "suggested_stop": null,
    "suggested_take_profit": null,
    "active_stop": null,
    "active_take_profit": null,
    "hypothetical_long_stop": 198.40,
    "hypothetical_long_take_profit": 217.92,
    "hypothetical_short_stop": 211.42,
    "hypothetical_short_take_profit": 191.90
  }
  ```

* **`live_state/signals_ledger_GOOG.csv`** – time series of decisions/positions (used for plots).

* **`live_state/pred_history_GOOG.csv`** – weekly predictions history used to compute leakage-safe percentiles.

---

## Figures (from `make_plots.py`)

* **Equity curve** vs **Buy & Hold** (unit exposure, didactic) – `figs/equity_curve.png`
* **Drawdown** – `figs/drawdown.png`
* **Signals (last \~6 months)** – `figs/signals_last_6m.png`

> These provide visual evidence of behavior and risk; you can extend the plotting script to compute CAGR, vol, Sharpe, max DD, turnover, hit rate, etc.

---

## Research Design Highlights

* **Hypothesis:** Short-horizon returns in a liquid mega-cap like GOOG show weak but usable structure from trend & volatility contexts; gradient boosting captures non-linear interactions better than linear baselines.

* **Evaluation plan (recommended in `report.md`):**

  * Walk-forward backtest (2018–2025), weekly cadence. Retrain each Friday on prior 252 labeled days.
  * Compare to **Buy & Hold**, SMA(50/200) long-only, and pure momentum (126-day).
  * Ablations: without regime filter; different thresholds; long-only vs long/short.
  * Stability: rolling 12-month Sharpe; sensitivity to LOOKBACK/HORIZON/thresholds.

* **Limitations:** Single-name risk, non-stationarity, simple cost model (you can add slippage/fees). Educational only; **not investment advice**.

---

## Troubleshooting

* **Yahoo “Too Many Requests”**: This repo includes a fallback to **Stooq** via `pandas-datareader`. Make sure you installed it (`conda install -c conda-forge pandas-datareader`).
* **Weekly rebalance not triggering**: Ensure timestamps are **normalized to midnight** (handled in code).
* **No new rows appended**: Check your `data/goog_historical_data.csv` last date; the script backfills strictly **after** the last date.
* **Different tickers**: Change `TICKER`/`ALT_TICKER`.

---

## How This Meets the Grading Rubric (50 pts)

* **Problem Description (10/10):** Clear goal, asset, horizon, cadence, multi-level mapping, regime filter.
* **Data Prep & Pipeline (10/10):** Robust loader (CSV→Yahoo→GOOGL→Stooq), normalization, timestamp alignment, feature set, leakage controls.
* **Research Design (10/10):** Hypothesis, model rationale, policy thresholds, regime logic, evaluation and ablations plan.
* **Programming (10/10):** Single, stateful program with reproducible outputs; plotting helper; environment file; clean repo structure.
* **Exposition (10/10):** `report.md` → `report.pdf`, figures, explanations, README quick-start & usage.

---

## Reproduce Exactly

```bash
conda env create -f environment.yml
conda activate goog-trader
python Google_Trading.py          # produces live_state/* files
python make_plots.py              # produces figs/*
# export report.md -> report.pdf (VS Code or Pandoc)
```

---

## Acknowledgments & References

* scikit-learn: HistGradientBoostingRegressor
* yfinance, pandas-datareader (Stooq)
* Classic TA definitions: RSI, MACD, ATR, Bollinger Bands

---

## Disclaimer

This project is for **educational purposes** only and does **not** constitute financial advice or a recommendation to trade any security. Use at your own risk.
